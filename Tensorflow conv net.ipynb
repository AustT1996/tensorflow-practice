{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a simple conv net from scratch in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, X, Y):\n",
    "    indices = np.random.randint(X.shape[0], size=batch_size)\n",
    "    X_ = X[indices]\n",
    "    y_ = Y[indices]\n",
    "    return X_, y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = mnist.train.images.shape\n",
    "output_shape = mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cnn_mnist_try01\"\n",
    "n_epochs = 2\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dir = os.path.join('.', 'models', name)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(101)\n",
    "\n",
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "# Network architecture\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    # Inputs and outputs\n",
    "    X_raw = tf.placeholder(tf.float32, shape=(None, input_shape[1]), name=\"X_raw\")\n",
    "    X_in = tf.reshape(X_raw, shape=[-1, height, width, channels])\n",
    "    Y_raw = tf.placeholder(tf.int32, shape=(None), name=\"Y_raw\")\n",
    "    Y_in = tf.argmax(Y_raw, axis=1)\n",
    "#     Y_in = tf.placeholder(tf.int32, shape=(None), name=\"Y_in\")\n",
    "\n",
    "    # Hidden layers\n",
    "    c1 = tf.layers.conv2d(X_in, filters=30, kernel_size=7, padding=\"same\", \n",
    "                          name=\"c1\", activation=tf.nn.elu)\n",
    "    c2 = tf.layers.conv2d(c1, 25, 5, padding=\"same\", strides=2, \n",
    "                          name=\"c2\", activation=tf.nn.elu)\n",
    "    pool1 = tf.layers.max_pooling2d(c2, 10, strides=2, padding=\"same\", \n",
    "                                    name=\"pool1\")\n",
    "    c3 = tf.layers.conv2d(pool1, 2, 2, padding=\"same\", name=\"c3\", \n",
    "                          activation=tf.nn.elu)\n",
    "    \n",
    "    # Flatten layers\n",
    "    dim = c3.get_shape()\n",
    "#     dim = tf.reduce_prod(tf.shape(c3)[1:])\n",
    "    c3_flat = tf.reshape(c3, shape=[-1, dim[1]*dim[2]*dim[3]])\n",
    "\n",
    "    output = tf.layers.dense(c3_flat, output_shape[1], activation=tf.nn.elu, \n",
    "                             name=\"output\")\n",
    "    y_prob = tf.nn.softmax(output, name=\"y_proba\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=Y_in)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(output, Y_in, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "with tf.name_scope(\"admin\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches per epoch: 5500\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\cnn_mnist_try01\\cnn_mnist_try01.ckpt0\n",
      "Epoch 1 Batch 0: loss=9.510e-03\n",
      "Epoch 1 Batch 1000: loss=5.857e-03\n",
      "Epoch 1 Batch 2000: loss=6.561e-03\n",
      "Epoch 1 Batch 3000: loss=3.685e-01\n",
      "Epoch 1 Batch 4000: loss=3.820e-01\n",
      "Epoch 1 Batch 5000: loss=2.289e-02\n"
     ]
    }
   ],
   "source": [
    "RESTORE = 0\n",
    "n_batches = mnist.train.images.shape[0] // batch_size\n",
    "print(\"Number of Batches per epoch: {}\".format(n_batches))\n",
    "\n",
    "def get_ckpt_name(epoch):\n",
    "    return os.path.join(model_dir, name)+\".ckpt{}\".format(epoch)\n",
    "\n",
    "global_train_num = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Restore session\n",
    "    if RESTORE >= 0:\n",
    "        saver.restore(sess, get_ckpt_name(RESTORE))\n",
    "        start_epoch = RESTORE + 1\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "\n",
    "        # Run batches\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_val =                 sess.run([training_op, loss], \n",
    "                         feed_dict={X_raw: X_batch, Y_raw: Y_batch})\n",
    "            global_train_num += 1\n",
    "            \n",
    "            if batch_index % 1000 == 0:\n",
    "                print(\"Epoch {} Batch {}: loss={:.3e}\".\n",
    "                      format(epoch, batch_index,loss_val))\n",
    "\n",
    "        # Run validation\n",
    "        test_loss_val = sess.run(accuracy, feed_dict={X_raw: mnist.test.images, \n",
    "                                                      Y_raw: mnist.test.labels})\n",
    "\n",
    "        # print summary\n",
    "        if epoch % 10 == 0:\n",
    "            saver.save(sess, get_ckpt_name(epoch))\n",
    "            print(\"Epoch #{}:\\tTrain Loss: {:.2e}\\tTest Loss: {:.2e}\".\n",
    "                  format(epoch, loss_val, test_loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1714d39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[3000].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\models\\cnn_mnist_try01\\cnn_mnist_try01.ckpt0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, get_ckpt_name(0))\n",
    "    result = sess.run(y_prob, feed_dict={X_raw: mnist.test.images[3000:3001]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same thing but with keras for the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import \\\n",
    "    Dense, Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "from tensorflow.python.keras.metrics import categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0 l=2.39e+00 a=1.00e-01\n",
      "\tTest 0 l=2.2313125133514404, a=0.1979999989271164\n",
      "Batch: 1 l=2.26e+00 a=1.60e-01\n",
      "Batch: 2 l=2.07e+00 a=1.00e-01\n",
      "Batch: 3 l=2.00e+00 a=3.20e-01\n",
      "Batch: 4 l=1.95e+00 a=4.20e-01\n",
      "Batch: 5 l=1.74e+00 a=5.00e-01\n",
      "Batch: 6 l=1.70e+00 a=4.60e-01\n",
      "Batch: 7 l=1.59e+00 a=6.40e-01\n",
      "Batch: 8 l=1.47e+00 a=6.80e-01\n",
      "Batch: 9 l=1.30e+00 a=7.00e-01\n",
      "Batch: 10 l=1.17e+00 a=6.40e-01\n",
      "Batch: 11 l=8.96e-01 a=8.00e-01\n",
      "Batch: 12 l=8.23e-01 a=7.60e-01\n",
      "Batch: 13 l=7.34e-01 a=7.60e-01\n",
      "Batch: 14 l=8.87e-01 a=7.00e-01\n",
      "Batch: 15 l=7.94e-01 a=7.00e-01\n",
      "Batch: 16 l=6.95e-01 a=8.00e-01\n",
      "Batch: 17 l=7.12e-01 a=8.00e-01\n",
      "Batch: 18 l=5.19e-01 a=8.20e-01\n",
      "Batch: 19 l=5.65e-01 a=8.40e-01\n",
      "Batch: 20 l=4.58e-01 a=8.60e-01\n",
      "Batch: 21 l=4.91e-01 a=8.40e-01\n",
      "Batch: 22 l=3.90e-01 a=8.60e-01\n",
      "Batch: 23 l=6.37e-01 a=8.20e-01\n",
      "Batch: 24 l=5.41e-01 a=7.60e-01\n",
      "Batch: 25 l=4.07e-01 a=8.40e-01\n",
      "Batch: 26 l=7.85e-01 a=8.00e-01\n",
      "Batch: 27 l=5.48e-01 a=8.00e-01\n",
      "Batch: 28 l=5.16e-01 a=8.80e-01\n",
      "Batch: 29 l=5.87e-01 a=7.80e-01\n",
      "Batch: 30 l=3.95e-01 a=9.40e-01\n",
      "Batch: 31 l=7.58e-01 a=7.80e-01\n",
      "Batch: 32 l=4.16e-01 a=8.40e-01\n",
      "Batch: 33 l=3.76e-01 a=8.20e-01\n",
      "Batch: 34 l=2.78e-01 a=8.40e-01\n",
      "Batch: 35 l=4.96e-01 a=8.80e-01\n",
      "Batch: 36 l=2.93e-01 a=9.20e-01\n",
      "Batch: 37 l=2.17e-01 a=9.20e-01\n",
      "Batch: 38 l=3.22e-01 a=8.80e-01\n",
      "Batch: 39 l=3.16e-01 a=8.80e-01\n",
      "Batch: 40 l=5.60e-01 a=7.80e-01\n",
      "Batch: 41 l=7.45e-01 a=7.60e-01\n",
      "Batch: 42 l=4.19e-01 a=8.60e-01\n",
      "Batch: 43 l=5.06e-01 a=8.40e-01\n",
      "Batch: 44 l=5.52e-01 a=8.60e-01\n",
      "Batch: 45 l=5.23e-01 a=8.40e-01\n",
      "Batch: 46 l=4.53e-01 a=9.00e-01\n",
      "Batch: 47 l=3.41e-01 a=9.40e-01\n",
      "Batch: 48 l=5.58e-01 a=8.20e-01\n",
      "Batch: 49 l=3.91e-01 a=8.40e-01\n",
      "Batch: 50 l=4.69e-01 a=8.60e-01\n",
      "Batch: 51 l=8.04e-01 a=7.80e-01\n",
      "Batch: 52 l=1.86e-01 a=9.40e-01\n",
      "Batch: 53 l=3.13e-01 a=8.60e-01\n",
      "Batch: 54 l=5.35e-01 a=8.60e-01\n",
      "Batch: 55 l=2.86e-01 a=9.20e-01\n",
      "Batch: 56 l=3.60e-01 a=9.20e-01\n",
      "Batch: 57 l=3.58e-01 a=8.80e-01\n",
      "Batch: 58 l=4.91e-01 a=8.00e-01\n",
      "Batch: 59 l=2.71e-01 a=9.20e-01\n",
      "Batch: 60 l=2.46e-01 a=9.20e-01\n",
      "Batch: 61 l=3.09e-01 a=8.40e-01\n",
      "Batch: 62 l=2.21e-01 a=9.40e-01\n",
      "Batch: 63 l=3.28e-01 a=8.80e-01\n",
      "Batch: 64 l=3.13e-01 a=9.20e-01\n",
      "Batch: 65 l=5.22e-01 a=8.80e-01\n",
      "Batch: 66 l=2.85e-01 a=9.00e-01\n",
      "Batch: 67 l=2.69e-01 a=9.20e-01\n",
      "Batch: 68 l=3.95e-01 a=8.80e-01\n",
      "Batch: 69 l=3.92e-01 a=9.20e-01\n",
      "Batch: 70 l=4.30e-01 a=8.40e-01\n",
      "Batch: 71 l=3.48e-01 a=8.80e-01\n",
      "Batch: 72 l=4.82e-01 a=8.60e-01\n",
      "Batch: 73 l=2.59e-01 a=9.20e-01\n",
      "Batch: 74 l=3.91e-01 a=9.00e-01\n",
      "Batch: 75 l=2.65e-01 a=9.20e-01\n",
      "Batch: 76 l=3.69e-01 a=9.40e-01\n",
      "Batch: 77 l=3.26e-01 a=8.80e-01\n",
      "Batch: 78 l=2.80e-01 a=9.00e-01\n",
      "Batch: 79 l=4.73e-01 a=8.40e-01\n",
      "Batch: 80 l=4.83e-01 a=8.60e-01\n",
      "Batch: 81 l=4.39e-01 a=9.00e-01\n",
      "Batch: 82 l=9.07e-02 a=9.80e-01\n",
      "Batch: 83 l=3.17e-01 a=9.20e-01\n",
      "Batch: 84 l=1.15e-01 a=9.60e-01\n",
      "Batch: 85 l=3.80e-01 a=8.80e-01\n",
      "Batch: 86 l=2.53e-01 a=9.20e-01\n",
      "Batch: 87 l=3.73e-01 a=9.00e-01\n",
      "Batch: 88 l=5.35e-01 a=7.80e-01\n",
      "Batch: 89 l=3.90e-01 a=9.00e-01\n",
      "Batch: 90 l=2.08e-01 a=9.40e-01\n",
      "Batch: 91 l=3.42e-01 a=9.40e-01\n",
      "Batch: 92 l=3.61e-01 a=8.40e-01\n",
      "Batch: 93 l=2.28e-01 a=9.40e-01\n",
      "Batch: 94 l=3.30e-01 a=8.80e-01\n",
      "Batch: 95 l=4.09e-01 a=9.00e-01\n",
      "Batch: 96 l=4.52e-01 a=8.40e-01\n",
      "Batch: 97 l=1.63e-01 a=9.60e-01\n",
      "Batch: 98 l=2.92e-01 a=9.00e-01\n",
      "Batch: 99 l=3.31e-01 a=8.60e-01\n",
      "Batch: 100 l=2.11e-01 a=9.40e-01\n",
      "\tTest 100 l=0.28810665011405945, a=0.9319999814033508\n",
      "Batch: 101 l=2.16e-01 a=9.20e-01\n",
      "Batch: 102 l=3.87e-01 a=8.60e-01\n",
      "Batch: 103 l=2.60e-01 a=9.00e-01\n",
      "Batch: 104 l=2.34e-01 a=9.40e-01\n",
      "Batch: 105 l=4.86e-01 a=8.40e-01\n",
      "Batch: 106 l=2.95e-01 a=9.00e-01\n",
      "Batch: 107 l=2.88e-01 a=9.20e-01\n",
      "Batch: 108 l=1.85e-01 a=9.40e-01\n",
      "Batch: 109 l=2.96e-01 a=9.00e-01\n",
      "Batch: 110 l=2.74e-01 a=9.60e-01\n",
      "Batch: 111 l=1.47e-01 a=9.60e-01\n",
      "Batch: 112 l=3.02e-01 a=9.00e-01\n",
      "Batch: 113 l=3.47e-01 a=8.60e-01\n",
      "Batch: 114 l=3.10e-01 a=8.80e-01\n",
      "Batch: 115 l=2.31e-01 a=9.00e-01\n",
      "Batch: 116 l=2.82e-01 a=9.40e-01\n",
      "Batch: 117 l=1.69e-01 a=9.40e-01\n",
      "Batch: 118 l=5.22e-01 a=8.80e-01\n",
      "Batch: 119 l=2.21e-01 a=9.00e-01\n",
      "Batch: 120 l=5.00e-01 a=9.00e-01\n",
      "Batch: 121 l=3.07e-01 a=9.00e-01\n",
      "Batch: 122 l=1.53e-01 a=9.60e-01\n",
      "Batch: 123 l=2.16e-01 a=9.20e-01\n",
      "Batch: 124 l=1.53e-01 a=9.00e-01\n",
      "Batch: 125 l=1.96e-01 a=9.20e-01\n",
      "Batch: 126 l=2.27e-01 a=9.40e-01\n",
      "Batch: 127 l=3.48e-01 a=9.20e-01\n",
      "Batch: 128 l=4.34e-01 a=8.80e-01\n",
      "Batch: 129 l=8.30e-02 a=9.80e-01\n",
      "Batch: 130 l=2.89e-01 a=8.80e-01\n",
      "Batch: 131 l=2.91e-01 a=9.00e-01\n",
      "Batch: 132 l=2.06e-01 a=9.60e-01\n",
      "Batch: 133 l=1.34e-01 a=9.60e-01\n",
      "Batch: 134 l=5.79e-01 a=9.00e-01\n",
      "Batch: 135 l=1.56e-01 a=9.80e-01\n",
      "Batch: 136 l=1.95e-01 a=9.40e-01\n",
      "Batch: 137 l=2.66e-01 a=8.80e-01\n",
      "Batch: 138 l=3.93e-01 a=9.40e-01\n",
      "Batch: 139 l=2.54e-01 a=9.00e-01\n",
      "Batch: 140 l=2.45e-01 a=9.20e-01\n",
      "Batch: 141 l=3.68e-01 a=8.60e-01\n",
      "Batch: 142 l=1.34e-01 a=9.60e-01\n",
      "Batch: 143 l=1.59e-01 a=9.60e-01\n",
      "Batch: 144 l=1.48e-01 a=9.40e-01\n",
      "Batch: 145 l=3.07e-01 a=9.20e-01\n",
      "Batch: 146 l=2.26e-01 a=8.80e-01\n",
      "Batch: 147 l=4.64e-01 a=9.40e-01\n",
      "Batch: 148 l=2.88e-01 a=9.40e-01\n",
      "Batch: 149 l=1.73e-01 a=9.40e-01\n",
      "Batch: 150 l=4.23e-01 a=8.60e-01\n",
      "Batch: 151 l=2.60e-01 a=8.80e-01\n",
      "Batch: 152 l=1.58e-01 a=9.40e-01\n",
      "Batch: 153 l=3.63e-01 a=9.00e-01\n",
      "Batch: 154 l=4.93e-01 a=8.60e-01\n",
      "Batch: 155 l=3.65e-01 a=9.00e-01\n",
      "Batch: 156 l=2.65e-01 a=9.00e-01\n",
      "Batch: 157 l=1.14e-01 a=9.60e-01\n",
      "Batch: 158 l=1.92e-01 a=9.60e-01\n",
      "Batch: 159 l=1.43e-01 a=9.40e-01\n",
      "Batch: 160 l=1.58e-01 a=9.60e-01\n",
      "Batch: 161 l=2.13e-01 a=9.40e-01\n",
      "Batch: 162 l=2.52e-01 a=9.40e-01\n",
      "Batch: 163 l=1.15e-01 a=9.60e-01\n",
      "Batch: 164 l=1.24e-01 a=9.20e-01\n",
      "Batch: 165 l=1.86e-01 a=9.20e-01\n",
      "Batch: 166 l=1.93e-01 a=9.60e-01\n",
      "Batch: 167 l=8.90e-02 a=1.00e+00\n",
      "Batch: 168 l=1.14e-01 a=9.60e-01\n",
      "Batch: 169 l=2.07e-01 a=9.40e-01\n",
      "Batch: 170 l=1.51e-01 a=9.60e-01\n",
      "Batch: 171 l=2.26e-01 a=9.40e-01\n",
      "Batch: 172 l=3.23e-01 a=9.60e-01\n",
      "Batch: 173 l=1.86e-01 a=9.20e-01\n",
      "Batch: 174 l=1.18e-01 a=9.60e-01\n",
      "Batch: 175 l=2.42e-01 a=9.40e-01\n",
      "Batch: 176 l=3.08e-01 a=9.20e-01\n",
      "Batch: 177 l=3.23e-01 a=9.60e-01\n",
      "Batch: 178 l=2.43e-01 a=9.20e-01\n",
      "Batch: 179 l=2.28e-01 a=9.60e-01\n",
      "Batch: 180 l=2.59e-01 a=9.20e-01\n",
      "Batch: 181 l=1.62e-01 a=9.40e-01\n",
      "Batch: 182 l=2.19e-01 a=9.60e-01\n",
      "Batch: 183 l=2.16e-01 a=9.40e-01\n",
      "Batch: 184 l=2.16e-01 a=9.40e-01\n",
      "Batch: 185 l=1.34e-01 a=9.60e-01\n",
      "Batch: 186 l=2.13e-01 a=8.80e-01\n",
      "Batch: 187 l=4.96e-01 a=8.20e-01\n",
      "Batch: 188 l=1.84e-01 a=9.60e-01\n",
      "Batch: 189 l=3.36e-01 a=9.00e-01\n",
      "Batch: 190 l=1.51e-01 a=9.40e-01\n",
      "Batch: 191 l=1.84e-01 a=9.40e-01\n",
      "Batch: 192 l=6.59e-02 a=1.00e+00\n",
      "Batch: 193 l=4.86e-02 a=1.00e+00\n",
      "Batch: 194 l=8.75e-02 a=9.80e-01\n",
      "Batch: 195 l=4.84e-01 a=9.20e-01\n",
      "Batch: 196 l=1.20e-01 a=9.80e-01\n",
      "Batch: 197 l=1.00e-01 a=9.60e-01\n",
      "Batch: 198 l=1.69e-01 a=9.00e-01\n",
      "Batch: 199 l=1.97e-01 a=9.20e-01\n",
      "Batch: 200 l=1.40e-01 a=9.40e-01\n",
      "\tTest 200 l=0.1370246857404709, a=0.9679999947547913\n",
      "Batch: 201 l=1.49e-01 a=9.80e-01\n",
      "Batch: 202 l=2.89e-01 a=9.20e-01\n",
      "Batch: 203 l=2.81e-01 a=9.20e-01\n",
      "Batch: 204 l=1.57e-01 a=9.40e-01\n",
      "Batch: 205 l=1.08e-01 a=9.80e-01\n",
      "Batch: 206 l=1.80e-01 a=9.40e-01\n",
      "Batch: 207 l=1.56e-01 a=9.40e-01\n",
      "Batch: 208 l=8.83e-02 a=9.60e-01\n",
      "Batch: 209 l=5.59e-02 a=1.00e+00\n",
      "Batch: 210 l=1.29e-01 a=9.60e-01\n",
      "Batch: 211 l=1.97e-01 a=9.40e-01\n",
      "Batch: 212 l=3.87e-01 a=9.00e-01\n",
      "Batch: 213 l=3.28e-01 a=9.40e-01\n",
      "Batch: 214 l=2.53e-01 a=9.40e-01\n",
      "Batch: 215 l=2.98e-01 a=9.00e-01\n",
      "Batch: 216 l=1.16e-01 a=9.80e-01\n",
      "Batch: 217 l=1.39e-01 a=9.80e-01\n",
      "Batch: 218 l=2.25e-01 a=9.40e-01\n",
      "Batch: 219 l=3.39e-01 a=9.00e-01\n",
      "Batch: 220 l=1.97e-01 a=9.40e-01\n",
      "Batch: 221 l=1.43e-01 a=9.40e-01\n",
      "Batch: 222 l=2.73e-01 a=8.80e-01\n",
      "Batch: 223 l=1.27e-01 a=9.60e-01\n",
      "Batch: 224 l=1.10e-01 a=9.60e-01\n",
      "Batch: 225 l=1.07e-01 a=9.60e-01\n",
      "Batch: 226 l=1.04e-01 a=9.80e-01\n",
      "Batch: 227 l=5.09e-02 a=1.00e+00\n",
      "Batch: 228 l=1.59e-01 a=9.60e-01\n",
      "Batch: 229 l=1.54e-01 a=9.60e-01\n",
      "Batch: 230 l=1.02e-01 a=9.60e-01\n",
      "Batch: 231 l=1.43e-01 a=9.20e-01\n",
      "Batch: 232 l=5.79e-02 a=9.80e-01\n",
      "Batch: 233 l=2.59e-01 a=9.40e-01\n",
      "Batch: 234 l=3.16e-01 a=9.40e-01\n",
      "Batch: 235 l=4.85e-02 a=1.00e+00\n",
      "Batch: 236 l=1.23e-01 a=9.60e-01\n",
      "Batch: 237 l=1.08e-01 a=9.80e-01\n",
      "Batch: 238 l=8.27e-02 a=9.80e-01\n",
      "Batch: 239 l=8.64e-02 a=9.60e-01\n",
      "Batch: 240 l=2.24e-01 a=9.40e-01\n",
      "Batch: 241 l=1.25e-01 a=9.80e-01\n",
      "Batch: 242 l=1.37e-01 a=9.80e-01\n",
      "Batch: 243 l=1.10e-01 a=9.60e-01\n",
      "Batch: 244 l=1.24e-01 a=9.80e-01\n",
      "Batch: 245 l=5.85e-02 a=9.60e-01\n",
      "Batch: 246 l=9.29e-02 a=9.80e-01\n",
      "Batch: 247 l=1.21e-01 a=9.60e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 248 l=3.20e-01 a=9.40e-01\n",
      "Batch: 249 l=4.01e-01 a=9.00e-01\n",
      "Batch: 250 l=5.47e-02 a=9.80e-01\n",
      "Batch: 251 l=9.29e-02 a=9.60e-01\n",
      "Batch: 252 l=3.98e-01 a=8.60e-01\n",
      "Batch: 253 l=3.98e-01 a=9.40e-01\n",
      "Batch: 254 l=1.83e-01 a=9.40e-01\n",
      "Batch: 255 l=7.25e-02 a=9.80e-01\n",
      "Batch: 256 l=1.89e-01 a=9.40e-01\n",
      "Batch: 257 l=1.50e-01 a=9.60e-01\n",
      "Batch: 258 l=3.48e-02 a=9.80e-01\n",
      "Batch: 259 l=1.53e-01 a=9.80e-01\n",
      "Batch: 260 l=2.27e-01 a=9.40e-01\n",
      "Batch: 261 l=9.06e-02 a=9.80e-01\n",
      "Batch: 262 l=1.45e-01 a=9.20e-01\n",
      "Batch: 263 l=6.37e-02 a=9.80e-01\n",
      "Batch: 264 l=1.50e-01 a=9.60e-01\n",
      "Batch: 265 l=2.45e-01 a=9.60e-01\n",
      "Batch: 266 l=3.99e-01 a=9.00e-01\n",
      "Batch: 267 l=2.70e-01 a=9.60e-01\n",
      "Batch: 268 l=1.38e-01 a=9.20e-01\n",
      "Batch: 269 l=2.57e-01 a=9.40e-01\n",
      "Batch: 270 l=6.14e-02 a=9.80e-01\n",
      "Batch: 271 l=1.36e-01 a=9.60e-01\n",
      "Batch: 272 l=2.91e-01 a=9.00e-01\n",
      "Batch: 273 l=4.84e-02 a=1.00e+00\n",
      "Batch: 274 l=4.22e-02 a=9.80e-01\n",
      "Batch: 275 l=1.45e-01 a=9.40e-01\n",
      "Batch: 276 l=1.80e-01 a=9.20e-01\n",
      "Batch: 277 l=6.40e-02 a=9.80e-01\n",
      "Batch: 278 l=1.38e-01 a=9.40e-01\n",
      "Batch: 279 l=2.26e-01 a=9.20e-01\n",
      "Batch: 280 l=1.47e-01 a=9.60e-01\n",
      "Batch: 281 l=2.63e-01 a=8.80e-01\n",
      "Batch: 282 l=6.10e-02 a=9.80e-01\n",
      "Batch: 283 l=5.63e-02 a=9.80e-01\n",
      "Batch: 284 l=6.57e-01 a=8.80e-01\n",
      "Batch: 285 l=3.96e-02 a=1.00e+00\n",
      "Batch: 286 l=2.70e-01 a=9.00e-01\n",
      "Batch: 287 l=2.92e-01 a=9.00e-01\n",
      "Batch: 288 l=2.00e-01 a=9.40e-01\n",
      "Batch: 289 l=1.67e-01 a=9.60e-01\n",
      "Batch: 290 l=4.11e-02 a=9.80e-01\n",
      "Batch: 291 l=5.12e-02 a=9.80e-01\n",
      "Batch: 292 l=1.15e-01 a=9.80e-01\n",
      "Batch: 293 l=2.00e-01 a=9.00e-01\n",
      "Batch: 294 l=1.45e-01 a=9.60e-01\n",
      "Batch: 295 l=1.08e-01 a=9.80e-01\n",
      "Batch: 296 l=1.49e-01 a=9.40e-01\n",
      "Batch: 297 l=4.92e-02 a=9.80e-01\n",
      "Batch: 298 l=2.17e-01 a=9.40e-01\n",
      "Batch: 299 l=1.26e-01 a=9.60e-01\n",
      "Batch: 300 l=7.23e-02 a=9.80e-01\n",
      "\tTest 300 l=0.09722900390625, a=0.9660000205039978\n",
      "Batch: 301 l=3.88e-01 a=9.20e-01\n",
      "Batch: 302 l=1.22e-01 a=9.40e-01\n",
      "Batch: 303 l=5.71e-02 a=1.00e+00\n",
      "Batch: 304 l=1.18e-01 a=9.40e-01\n",
      "Batch: 305 l=1.68e-01 a=9.20e-01\n",
      "Batch: 306 l=3.97e-02 a=1.00e+00\n",
      "Batch: 307 l=2.05e-01 a=9.60e-01\n",
      "Batch: 308 l=1.67e-01 a=9.80e-01\n",
      "Batch: 309 l=1.71e-01 a=9.60e-01\n",
      "Batch: 310 l=9.86e-02 a=9.60e-01\n",
      "Batch: 311 l=8.93e-02 a=9.60e-01\n",
      "Batch: 312 l=4.77e-02 a=9.80e-01\n",
      "Batch: 313 l=2.13e-01 a=9.00e-01\n",
      "Batch: 314 l=1.86e-02 a=1.00e+00\n",
      "Batch: 315 l=7.42e-02 a=9.80e-01\n",
      "Batch: 316 l=1.13e-01 a=9.40e-01\n",
      "Batch: 317 l=1.36e-01 a=9.60e-01\n",
      "Batch: 318 l=7.20e-02 a=9.80e-01\n",
      "Batch: 319 l=1.56e-01 a=9.20e-01\n",
      "Batch: 320 l=3.59e-01 a=9.20e-01\n",
      "Batch: 321 l=6.49e-02 a=9.80e-01\n",
      "Batch: 322 l=8.67e-02 a=9.80e-01\n",
      "Batch: 323 l=8.22e-02 a=9.80e-01\n",
      "Batch: 324 l=6.57e-02 a=9.80e-01\n",
      "Batch: 325 l=1.79e-02 a=1.00e+00\n",
      "Batch: 326 l=6.47e-02 a=9.80e-01\n",
      "Batch: 327 l=1.82e-02 a=1.00e+00\n",
      "Batch: 328 l=1.40e-01 a=9.60e-01\n",
      "Batch: 329 l=1.23e-01 a=9.40e-01\n",
      "Batch: 330 l=5.72e-02 a=1.00e+00\n",
      "Batch: 331 l=1.37e-01 a=9.60e-01\n",
      "Batch: 332 l=2.01e-01 a=9.20e-01\n",
      "Batch: 333 l=6.84e-02 a=1.00e+00\n",
      "Batch: 334 l=1.45e-01 a=9.60e-01\n",
      "Batch: 335 l=1.86e-01 a=9.20e-01\n",
      "Batch: 336 l=2.40e-01 a=8.80e-01\n",
      "Batch: 337 l=1.22e-01 a=9.80e-01\n",
      "Batch: 338 l=2.49e-01 a=9.20e-01\n",
      "Batch: 339 l=1.32e-01 a=9.60e-01\n",
      "Batch: 340 l=2.46e-01 a=9.40e-01\n",
      "Batch: 341 l=9.54e-02 a=9.60e-01\n",
      "Batch: 342 l=8.71e-02 a=9.80e-01\n",
      "Batch: 343 l=2.07e-01 a=9.60e-01\n",
      "Batch: 344 l=1.67e-01 a=9.40e-01\n",
      "Batch: 345 l=1.05e-01 a=9.80e-01\n",
      "Batch: 346 l=5.47e-02 a=9.80e-01\n",
      "Batch: 347 l=1.41e-01 a=9.60e-01\n",
      "Batch: 348 l=8.00e-02 a=9.60e-01\n",
      "Batch: 349 l=1.65e-01 a=9.40e-01\n",
      "Batch: 350 l=1.38e-01 a=9.40e-01\n",
      "Batch: 351 l=8.49e-02 a=9.60e-01\n",
      "Batch: 352 l=1.28e-01 a=9.60e-01\n",
      "Batch: 353 l=1.29e-01 a=9.60e-01\n",
      "Batch: 354 l=1.91e-01 a=9.20e-01\n",
      "Batch: 355 l=8.15e-02 a=9.80e-01\n",
      "Batch: 356 l=1.30e-01 a=9.60e-01\n",
      "Batch: 357 l=2.25e-01 a=9.20e-01\n",
      "Batch: 358 l=8.54e-02 a=9.60e-01\n",
      "Batch: 359 l=1.17e-01 a=9.40e-01\n",
      "Batch: 360 l=2.74e-02 a=1.00e+00\n",
      "Batch: 361 l=1.56e-01 a=9.40e-01\n",
      "Batch: 362 l=1.56e-01 a=9.40e-01\n",
      "Batch: 363 l=1.49e-01 a=9.40e-01\n",
      "Batch: 364 l=5.51e-02 a=1.00e+00\n",
      "Batch: 365 l=1.66e-01 a=9.40e-01\n",
      "Batch: 366 l=8.85e-02 a=9.80e-01\n",
      "Batch: 367 l=8.20e-02 a=9.80e-01\n",
      "Batch: 368 l=2.52e-02 a=1.00e+00\n",
      "Batch: 369 l=1.26e-01 a=9.60e-01\n",
      "Batch: 370 l=1.25e-01 a=9.60e-01\n",
      "Batch: 371 l=5.88e-02 a=9.80e-01\n",
      "Batch: 372 l=7.84e-02 a=9.60e-01\n",
      "Batch: 373 l=1.84e-01 a=9.20e-01\n",
      "Batch: 374 l=5.09e-02 a=9.80e-01\n",
      "Batch: 375 l=1.63e-01 a=9.40e-01\n",
      "Batch: 376 l=1.33e-01 a=9.80e-01\n",
      "Batch: 377 l=2.19e-01 a=9.40e-01\n",
      "Batch: 378 l=4.57e-02 a=9.80e-01\n",
      "Batch: 379 l=1.95e-01 a=9.20e-01\n",
      "Batch: 380 l=1.62e-01 a=9.40e-01\n",
      "Batch: 381 l=1.86e-01 a=9.60e-01\n",
      "Batch: 382 l=9.25e-02 a=9.60e-01\n",
      "Batch: 383 l=8.01e-02 a=9.60e-01\n",
      "Batch: 384 l=7.71e-02 a=9.80e-01\n",
      "Batch: 385 l=1.35e-01 a=9.40e-01\n",
      "Batch: 386 l=1.47e-01 a=9.60e-01\n",
      "Batch: 387 l=1.17e-01 a=9.60e-01\n",
      "Batch: 388 l=2.47e-01 a=9.20e-01\n",
      "Batch: 389 l=1.49e-01 a=9.60e-01\n",
      "Batch: 390 l=8.70e-02 a=9.80e-01\n",
      "Batch: 391 l=1.23e-01 a=9.60e-01\n",
      "Batch: 392 l=6.39e-02 a=9.60e-01\n",
      "Batch: 393 l=1.23e-01 a=9.80e-01\n",
      "Batch: 394 l=1.03e-01 a=9.60e-01\n",
      "Batch: 395 l=1.03e-01 a=9.80e-01\n",
      "Batch: 396 l=2.60e-01 a=9.40e-01\n",
      "Batch: 397 l=2.36e-01 a=9.80e-01\n",
      "Batch: 398 l=1.09e-01 a=9.60e-01\n",
      "Batch: 399 l=1.67e-02 a=1.00e+00\n",
      "Batch: 400 l=9.86e-03 a=1.00e+00\n",
      "\tTest 400 l=0.15530022978782654, a=0.9580000042915344\n",
      "Batch: 401 l=1.05e-01 a=9.60e-01\n",
      "Batch: 402 l=1.12e-01 a=9.60e-01\n",
      "Batch: 403 l=2.61e-01 a=9.00e-01\n",
      "Batch: 404 l=1.89e-01 a=9.40e-01\n",
      "Batch: 405 l=4.87e-02 a=9.80e-01\n",
      "Batch: 406 l=1.98e-01 a=9.60e-01\n",
      "Batch: 407 l=5.33e-02 a=9.80e-01\n",
      "Batch: 408 l=6.36e-02 a=9.80e-01\n",
      "Batch: 409 l=7.66e-02 a=9.60e-01\n",
      "Batch: 410 l=8.60e-02 a=9.60e-01\n",
      "Batch: 411 l=1.21e-01 a=9.60e-01\n",
      "Batch: 412 l=5.38e-02 a=9.80e-01\n",
      "Batch: 413 l=4.83e-02 a=9.80e-01\n",
      "Batch: 414 l=5.94e-02 a=9.80e-01\n",
      "Batch: 415 l=5.93e-02 a=9.80e-01\n",
      "Batch: 416 l=6.67e-02 a=9.60e-01\n",
      "Batch: 417 l=5.78e-02 a=1.00e+00\n",
      "Batch: 418 l=1.18e-01 a=9.60e-01\n",
      "Batch: 419 l=3.07e-02 a=1.00e+00\n",
      "Batch: 420 l=2.56e-01 a=9.60e-01\n",
      "Batch: 421 l=2.18e-01 a=9.40e-01\n",
      "Batch: 422 l=9.78e-03 a=1.00e+00\n",
      "Batch: 423 l=3.15e-02 a=1.00e+00\n",
      "Batch: 424 l=2.54e-02 a=1.00e+00\n",
      "Batch: 425 l=1.62e-01 a=9.40e-01\n",
      "Batch: 426 l=7.28e-02 a=9.80e-01\n",
      "Batch: 427 l=5.93e-02 a=9.80e-01\n",
      "Batch: 428 l=6.92e-02 a=9.80e-01\n",
      "Batch: 429 l=1.65e-01 a=9.80e-01\n",
      "Batch: 430 l=9.69e-02 a=9.80e-01\n",
      "Batch: 431 l=2.13e-01 a=9.20e-01\n",
      "Batch: 432 l=4.19e-01 a=9.40e-01\n",
      "Batch: 433 l=1.37e-01 a=9.60e-01\n",
      "Batch: 434 l=1.23e-01 a=9.60e-01\n",
      "Batch: 435 l=1.37e-01 a=9.60e-01\n",
      "Batch: 436 l=5.33e-02 a=9.80e-01\n",
      "Batch: 437 l=2.15e-01 a=9.00e-01\n",
      "Batch: 438 l=1.72e-01 a=9.60e-01\n",
      "Batch: 439 l=1.36e-01 a=9.80e-01\n",
      "Batch: 440 l=2.12e-02 a=1.00e+00\n",
      "Batch: 441 l=7.10e-02 a=9.60e-01\n",
      "Batch: 442 l=2.51e-02 a=1.00e+00\n",
      "Batch: 443 l=9.28e-02 a=9.80e-01\n",
      "Batch: 444 l=2.37e-01 a=9.40e-01\n",
      "Batch: 445 l=2.70e-02 a=1.00e+00\n",
      "Batch: 446 l=3.27e-02 a=9.80e-01\n",
      "Batch: 447 l=1.60e-02 a=1.00e+00\n",
      "Batch: 448 l=1.07e-01 a=9.60e-01\n",
      "Batch: 449 l=1.55e-01 a=9.60e-01\n",
      "Batch: 450 l=8.12e-02 a=9.60e-01\n",
      "Batch: 451 l=1.99e-01 a=9.40e-01\n",
      "Batch: 452 l=2.86e-02 a=1.00e+00\n",
      "Batch: 453 l=4.68e-02 a=9.80e-01\n",
      "Batch: 454 l=6.10e-02 a=9.80e-01\n",
      "Batch: 455 l=1.47e-01 a=9.60e-01\n",
      "Batch: 456 l=9.25e-02 a=9.60e-01\n",
      "Batch: 457 l=8.68e-02 a=9.80e-01\n",
      "Batch: 458 l=5.60e-02 a=9.80e-01\n",
      "Batch: 459 l=3.26e-02 a=1.00e+00\n",
      "Batch: 460 l=4.82e-01 a=9.00e-01\n",
      "Batch: 461 l=3.79e-02 a=1.00e+00\n",
      "Batch: 462 l=5.86e-02 a=9.80e-01\n",
      "Batch: 463 l=5.94e-02 a=9.80e-01\n",
      "Batch: 464 l=5.85e-02 a=1.00e+00\n",
      "Batch: 465 l=9.44e-02 a=9.60e-01\n",
      "Batch: 466 l=3.74e-02 a=9.80e-01\n",
      "Batch: 467 l=7.84e-02 a=9.80e-01\n",
      "Batch: 468 l=1.08e-01 a=9.60e-01\n",
      "Batch: 469 l=8.74e-02 a=9.60e-01\n",
      "Batch: 470 l=6.60e-02 a=9.60e-01\n",
      "Batch: 471 l=1.03e-01 a=9.60e-01\n",
      "Batch: 472 l=2.54e-01 a=9.20e-01\n",
      "Batch: 473 l=1.72e-01 a=9.60e-01\n",
      "Batch: 474 l=3.01e-02 a=9.80e-01\n",
      "Batch: 475 l=1.27e-02 a=1.00e+00\n",
      "Batch: 476 l=1.02e-01 a=9.80e-01\n",
      "Batch: 477 l=1.17e-01 a=9.80e-01\n",
      "Batch: 478 l=8.37e-03 a=1.00e+00\n",
      "Batch: 479 l=3.31e-02 a=9.80e-01\n",
      "Batch: 480 l=1.76e-01 a=9.60e-01\n",
      "Batch: 481 l=2.78e-02 a=9.80e-01\n",
      "Batch: 482 l=3.06e-01 a=9.60e-01\n",
      "Batch: 483 l=1.88e-01 a=9.60e-01\n",
      "Batch: 484 l=1.28e-01 a=9.80e-01\n",
      "Batch: 485 l=5.84e-02 a=9.80e-01\n",
      "Batch: 486 l=6.15e-02 a=9.80e-01\n",
      "Batch: 487 l=7.84e-02 a=9.80e-01\n",
      "Batch: 488 l=1.08e-01 a=9.60e-01\n",
      "Batch: 489 l=1.91e-02 a=1.00e+00\n",
      "Batch: 490 l=3.49e-01 a=8.80e-01\n",
      "Batch: 491 l=4.18e-02 a=9.80e-01\n",
      "Batch: 492 l=6.63e-02 a=9.80e-01\n",
      "Batch: 493 l=8.55e-02 a=9.60e-01\n",
      "Batch: 494 l=2.65e-02 a=1.00e+00\n",
      "Batch: 495 l=1.02e-01 a=9.80e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 496 l=8.68e-02 a=9.60e-01\n",
      "Batch: 497 l=1.29e-01 a=9.60e-01\n",
      "Batch: 498 l=9.67e-02 a=9.80e-01\n",
      "Batch: 499 l=4.86e-02 a=9.80e-01\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X_raw = tf.placeholder(tf.float32, shape=(None, input_shape[1]), name=\"X_raw\")\n",
    "X_in = tf.reshape(X_raw, shape=[-1, 28, 28, 1])\n",
    "Y_raw = tf.placeholder(tf.int32, shape=(None), name=\"Y_raw\")\n",
    "Y = tf.cast(Y_raw, tf.float32)\n",
    "# Y_in = tf.argmax(Y_raw, axis=1)\n",
    "\n",
    "c1 = Conv2D(32, kernel_size=(3,3),\n",
    "            activation='elu')(X_in)\n",
    "c2 = Conv2D(25, kernel_size=(3,3),\n",
    "            activation='elu')(c1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(c2)\n",
    "flat_conv = Flatten()(pool1)\n",
    "dense1 = Dense(64, activation='elu')(flat_conv)\n",
    "preds = Dense(10, activation='softmax')(dense1)\n",
    "\n",
    "loss = tf.reduce_mean(categorical_crossentropy(Y, preds))\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "accuracy = tf.reduce_mean(categorical_accuracy(Y, preds))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(500):\n",
    "        X_batch, Y_batch = mnist.train.next_batch(50)\n",
    "        _, l, a = sess.run([train_op, loss, accuracy], \n",
    "                          feed_dict={X_raw: X_batch, Y_raw: Y_batch})\n",
    "        print(\"Batch: {} l={:.2e} a={:.2e}\".format(i, l, a))\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            X_batch, Y_batch = mnist.test.next_batch(500)\n",
    "            l, a = sess.run([loss, accuracy], \n",
    "                          feed_dict={X_raw: X_batch, \n",
    "                                     Y_raw: Y_batch})\n",
    "            print(\"\\tTest {} l={}, a={}\".format(i, l, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
